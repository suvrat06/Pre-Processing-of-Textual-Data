{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHck06SrXNns"
   },
   "source": [
    "\n",
    "# Pre-Processing of Textual Data\n",
    "\n",
    "This notebook depicts the various steps involved in the pre-processing of textual data. In order to enuse smooth interpretation of text by machines a lot pre-processing is required - bag of words is done of the most popular ways to represent textual data for machines to process it. Here, I've taken a sample corpus (link provided at the end) which contains 10 txt files. We will be converting the corpus into bag of words (both count vector and tf-idf vector) through a series of steps. For the sake of understanding - the I've tried to perfom all the steps with and without in-built functions.\n",
    "\n",
    "Some important terms:\n",
    "\n",
    "**NLTK:** NLTK stands for Natural Language Tool Kit; it is popular library in python that is used for NLP and text prcoessing\n",
    "\n",
    "**Corpus:** A collection of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pVjo84RSZPDO"
   },
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import nltk\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "755Ktxv5dNIO"
   },
   "source": [
    "**Loading a corpus (of .txt files) :** <br> **1. File method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b71BcG1Pnj1S",
    "outputId": "4dcd1817-6fcd-4e18-cf37-e94f30861204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "#importing google drive in order to retrive the corpus\n",
    "from google.colab import drive \n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvBUjSbKo1-a",
    "outputId": "6b7ae170-bcb6-4b1a-94f1-1dff92ef5e9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file1.txt',\n",
       " 'file2.txt',\n",
       " 'file3.txt',\n",
       " 'file4.txt',\n",
       " 'file5.txt',\n",
       " 'file6.txt',\n",
       " 'file7.txt',\n",
       " 'file8.txt',\n",
       " 'file10.txt',\n",
       " 'file9.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = os.listdir(\"/content/gdrive/MyDrive/my_corpus\")\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M9zH2F-ppsNR",
    "outputId": "bc9508d0-4f06-425b-e76f-1e0e2f08dbf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.', 'The ideal characteristic of artificial intelligence is its ability to rationalize and take actions that have the best chance of achieving a specific goal. A subset of artificial intelligence is machine learning, which refers to the concept that computer programs can automatically learn from and adapt to new data without being assisted by humans. Deep learning techniques enable this automatic learning through the absorption of huge amounts of unstructured data such as text, images, or video.', \"When most people hear the term artificial intelligence, the first thing they usually think of is robots. That's because big-budget films and novels weave stories about human-like machines that wreak havoc on Earth. But nothing could be further from the truth.\", 'Artificial intelligence is based on the principle that human intelligence can be defined in a way that a machine can easily mimic it and execute tasks, from the most simple to those that are even more complex. The goals of artificial intelligence include mimicking human cognitive activity. Researchers and developers in the field are making surprisingly rapid strides in mimicking activities such as learning, reasoning, and perception, to the extent that these can be concretely defined. Some believe that innovators may soon be able to develop systems that exceed the capacity of humans to learn or reason out any subject. But others remain skeptical because all cognitive activity is laced with value judgments that are subject to human experience.', 'As technology advances, previous benchmarks that defined artificial intelligence become outdated. For example, machines that calculate basic functions or recognize text through optical character recognition are no longer considered to embody artificial intelligence, since this function is now taken for granted as an inherent computer function.', 'AI is continuously evolving to benefit many different industries. Machines are wired using a cross-disciplinary approach based on mathematics, computer science, linguistics, psychology, and more.\\n\\n', 'The applications for artificial intelligence are endless. The technology can be applied to many different sectors and industries. AI is being tested and used in the healthcare industry for dosing drugs and different treatment in patients, and for surgical procedures in the operating room.\\n\\n', 'Other examples of machines with artificial intelligence include computers that play chess and self-driving cars. Each of these machines must weigh the consequences of any action they take, as each action will impact the end result. In chess, the end result is winning the game. For self-driving cars, the computer system must account for all external data and compute it to act in a way that prevents a collision.', \"Artificial intelligence also has applications in the financial industry, where it is used to detect and flag activity in banking and finance such as unusual debit card usage and large account deposits—all of which help a bank's fraud department. Applications for AI are also being used to help streamline and make trading easier. This is done by making supply, demand, and pricing of securities easier to estimate.\", \"Artificial intelligence can be divided into two different categories: weak and strong. Weak artificial intelligence embodies a system designed to carry out one particular job. Weak AI systems include video games such as the chess example from above and personal assistants such as Amazon's Alexa and Apple's Siri. You ask the assistant a question, it answers it for you.\\n\\nStrong artificial intelligence systems are systems that carry on the tasks considered to be human-like. These tend to be more complex and complicated systems. They are programmed to handle situations in which they may be required to problem solve without having a person intervene. These kinds of systems can be found in applications like self-driving cars or in hospital operating rooms.\"]\n"
     ]
    }
   ],
   "source": [
    "content=list()\n",
    "for i in range(len(filenames)):\n",
    "  f=open(\"/content/gdrive/MyDrive/my_corpus/\"+filenames[i],'r')\n",
    "  text=f.read()\n",
    "  content.append(text)\n",
    "  f.close()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCxXE5bFe2I4"
   },
   "source": [
    "**2. PlaintextCorpusReader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JIm_Ut4ZdhMn",
    "outputId": "8e53336b-69dc-405f-e9b4-bb77d2db75be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PlaintextCorpusReader in '/content/gdrive/MyDrive/my_corpus'>\n",
      "['file1.txt', 'file10.txt', 'file2.txt', 'file3.txt', 'file4.txt', 'file5.txt', 'file6.txt', 'file7.txt', 'file8.txt', 'file9.txt']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "CorpusContent=PlaintextCorpusReader(\"/content/gdrive/MyDrive/my_corpus/\",'.*')\n",
    "print(CorpusContent)\n",
    "print(CorpusContent.fileids()) #fileids() returns the names of the files in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4w6wuxJeYxB",
    "outputId": "cba1ae66-202d-4c1a-8597-f75457def9d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.',\n",
       " \"Artificial intelligence also has applications in the financial industry, where it is used to detect and flag activity in banking and finance such as unusual debit card usage and large account deposits—all of which help a bank's fraud department. Applications for AI are also being used to help streamline and make trading easier. This is done by making supply, demand, and pricing of securities easier to estimate.\",\n",
       " 'The ideal characteristic of artificial intelligence is its ability to rationalize and take actions that have the best chance of achieving a specific goal. A subset of artificial intelligence is machine learning, which refers to the concept that computer programs can automatically learn from and adapt to new data without being assisted by humans. Deep learning techniques enable this automatic learning through the absorption of huge amounts of unstructured data such as text, images, or video.',\n",
       " \"When most people hear the term artificial intelligence, the first thing they usually think of is robots. That's because big-budget films and novels weave stories about human-like machines that wreak havoc on Earth. But nothing could be further from the truth.\",\n",
       " 'Artificial intelligence is based on the principle that human intelligence can be defined in a way that a machine can easily mimic it and execute tasks, from the most simple to those that are even more complex. The goals of artificial intelligence include mimicking human cognitive activity. Researchers and developers in the field are making surprisingly rapid strides in mimicking activities such as learning, reasoning, and perception, to the extent that these can be concretely defined. Some believe that innovators may soon be able to develop systems that exceed the capacity of humans to learn or reason out any subject. But others remain skeptical because all cognitive activity is laced with value judgments that are subject to human experience.',\n",
       " 'As technology advances, previous benchmarks that defined artificial intelligence become outdated. For example, machines that calculate basic functions or recognize text through optical character recognition are no longer considered to embody artificial intelligence, since this function is now taken for granted as an inherent computer function.',\n",
       " 'AI is continuously evolving to benefit many different industries. Machines are wired using a cross-disciplinary approach based on mathematics, computer science, linguistics, psychology, and more.\\r\\n\\r\\n',\n",
       " 'The applications for artificial intelligence are endless. The technology can be applied to many different sectors and industries. AI is being tested and used in the healthcare industry for dosing drugs and different treatment in patients, and for surgical procedures in the operating room.\\r\\n\\r\\n',\n",
       " 'Other examples of machines with artificial intelligence include computers that play chess and self-driving cars. Each of these machines must weigh the consequences of any action they take, as each action will impact the end result. In chess, the end result is winning the game. For self-driving cars, the computer system must account for all external data and compute it to act in a way that prevents a collision.',\n",
       " \"Artificial intelligence can be divided into two different categories: weak and strong. Weak artificial intelligence embodies a system designed to carry out one particular job. Weak AI systems include video games such as the chess example from above and personal assistants such as Amazon's Alexa and Apple's Siri. You ask the assistant a question, it answers it for you.\\r\\n\\r\\nStrong artificial intelligence systems are systems that carry on the tasks considered to be human-like. These tend to be more complex and complicated systems. They are programmed to handle situations in which they may be required to problem solve without having a person intervene. These kinds of systems can be found in applications like self-driving cars or in hospital operating rooms.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Content_final=[]\n",
    "for i in range(len(CorpusContent.fileids())):\n",
    "    Content_final.append(''.join(CorpusContent.raw(fileids=CorpusContent.fileids()[i])))\n",
    "Content_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCv80Wwwkszq"
   },
   "source": [
    "**Q2: Pre-process the corpus loaded in step 1 (apply Normalization, Tokenization, Stopword Removal, Stemming)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2daLM0qclPNM"
   },
   "source": [
    "**NORMALIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXdRJOwckuXg",
    "outputId": "2df1e6ad-0335-4eca-df17-5dee35de6123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artificial intelligence refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their the term may also be applied to any machine that exhibits traits associated with a human mind such as learning and', 'artificial intelligence also has applications in the financial where it is used to detect and flag activity in banking and finance such as unusual debit card usage and large account of which help a fraud applications for ai are also being used to help streamline and make trading this is done by making and pricing of securities easier to', 'the ideal characteristic of artificial intelligence is its ability to rationalize and take actions that have the best chance of achieving a specific a subset of artificial intelligence is machine which refers to the concept that computer programs can automatically learn from and adapt to new data without being assisted by deep learning techniques enable this automatic learning through the absorption of huge amounts of unstructured data such as or', 'when most people hear the term artificial the first thing they usually think of is because films and novels weave stories about machines that wreak havoc on but nothing could be further from the', 'artificial intelligence is based on the principle that human intelligence can be defined in a way that a machine can easily mimic it and execute from the most simple to those that are even more the goals of artificial intelligence include mimicking human cognitive researchers and developers in the field are making surprisingly rapid strides in mimicking activities such as and to the extent that these can be concretely some believe that innovators may soon be able to develop systems that exceed the capacity of humans to learn or reason out any but others remain skeptical because all cognitive activity is laced with value judgments that are subject to human', 'as technology previous benchmarks that defined artificial intelligence become for machines that calculate basic functions or recognize text through optical character recognition are no longer considered to embody artificial since this function is now taken for granted as an inherent computer', 'ai is continuously evolving to benefit many different machines are wired using a approach based on computer and', 'the applications for artificial intelligence are the technology can be applied to many different sectors and ai is being tested and used in the healthcare industry for dosing drugs and different treatment in and for surgical procedures in the operating', 'other examples of machines with artificial intelligence include computers that play chess and each of these machines must weigh the consequences of any action they as each action will impact the end in the end result is winning the for the computer system must account for all external data and compute it to act in a way that prevents a', 'artificial intelligence can be divided into two different weak and weak artificial intelligence embodies a system designed to carry out one particular weak ai systems include video games such as the chess example from above and personal assistants such as alexa and you ask the assistant a it answers it for strong artificial intelligence systems are systems that carry on the tasks considered to be these tend to be more complex and complicated they are programmed to handle situations in which they may be required to problem solve without having a person these kinds of systems can be found in applications like cars or in hospital operating']\n"
     ]
    }
   ],
   "source": [
    "normailzed_content=list()\n",
    "for i in range(len(Content_final)):\n",
    "  normailzed_content.append(' '.join([word.lower() for word in Content_final[i].split() if word.isalpha()]))\n",
    "print(normailzed_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFAgKJ6pnz8q"
   },
   "source": [
    "**TOKENIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUkVtVEQphLv",
    "outputId": "37ef21f2-dba7-4290-f7b4-dd56f39b7e3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') #downloading the necessary tokenizer (punkt tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y1u4b99CnSTr",
    "outputId": "63645012-b885-4582-bb0b-355d2d23f0de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['artificial', 'intelligence', 'refers', 'to', 'the', 'simulation', 'of', 'human', 'intelligence', 'in', 'machines', 'that', 'are', 'programmed', 'to', 'think', 'like', 'humans', 'and', 'mimic', 'their', 'the', 'term', 'may', 'also', 'be', 'applied', 'to', 'any', 'machine', 'that', 'exhibits', 'traits', 'associated', 'with', 'a', 'human', 'mind', 'such', 'as', 'learning', 'and'], ['artificial', 'intelligence', 'also', 'has', 'applications', 'in', 'the', 'financial', 'where', 'it', 'is', 'used', 'to', 'detect', 'and', 'flag', 'activity', 'in', 'banking', 'and', 'finance', 'such', 'as', 'unusual', 'debit', 'card', 'usage', 'and', 'large', 'account', 'of', 'which', 'help', 'a', 'fraud', 'applications', 'for', 'ai', 'are', 'also', 'being', 'used', 'to', 'help', 'streamline', 'and', 'make', 'trading', 'this', 'is', 'done', 'by', 'making', 'and', 'pricing', 'of', 'securities', 'easier', 'to'], ['the', 'ideal', 'characteristic', 'of', 'artificial', 'intelligence', 'is', 'its', 'ability', 'to', 'rationalize', 'and', 'take', 'actions', 'that', 'have', 'the', 'best', 'chance', 'of', 'achieving', 'a', 'specific', 'a', 'subset', 'of', 'artificial', 'intelligence', 'is', 'machine', 'which', 'refers', 'to', 'the', 'concept', 'that', 'computer', 'programs', 'can', 'automatically', 'learn', 'from', 'and', 'adapt', 'to', 'new', 'data', 'without', 'being', 'assisted', 'by', 'deep', 'learning', 'techniques', 'enable', 'this', 'automatic', 'learning', 'through', 'the', 'absorption', 'of', 'huge', 'amounts', 'of', 'unstructured', 'data', 'such', 'as', 'or'], ['when', 'most', 'people', 'hear', 'the', 'term', 'artificial', 'the', 'first', 'thing', 'they', 'usually', 'think', 'of', 'is', 'because', 'films', 'and', 'novels', 'weave', 'stories', 'about', 'machines', 'that', 'wreak', 'havoc', 'on', 'but', 'nothing', 'could', 'be', 'further', 'from', 'the'], ['artificial', 'intelligence', 'is', 'based', 'on', 'the', 'principle', 'that', 'human', 'intelligence', 'can', 'be', 'defined', 'in', 'a', 'way', 'that', 'a', 'machine', 'can', 'easily', 'mimic', 'it', 'and', 'execute', 'from', 'the', 'most', 'simple', 'to', 'those', 'that', 'are', 'even', 'more', 'the', 'goals', 'of', 'artificial', 'intelligence', 'include', 'mimicking', 'human', 'cognitive', 'researchers', 'and', 'developers', 'in', 'the', 'field', 'are', 'making', 'surprisingly', 'rapid', 'strides', 'in', 'mimicking', 'activities', 'such', 'as', 'and', 'to', 'the', 'extent', 'that', 'these', 'can', 'be', 'concretely', 'some', 'believe', 'that', 'innovators', 'may', 'soon', 'be', 'able', 'to', 'develop', 'systems', 'that', 'exceed', 'the', 'capacity', 'of', 'humans', 'to', 'learn', 'or', 'reason', 'out', 'any', 'but', 'others', 'remain', 'skeptical', 'because', 'all', 'cognitive', 'activity', 'is', 'laced', 'with', 'value', 'judgments', 'that', 'are', 'subject', 'to', 'human'], ['as', 'technology', 'previous', 'benchmarks', 'that', 'defined', 'artificial', 'intelligence', 'become', 'for', 'machines', 'that', 'calculate', 'basic', 'functions', 'or', 'recognize', 'text', 'through', 'optical', 'character', 'recognition', 'are', 'no', 'longer', 'considered', 'to', 'embody', 'artificial', 'since', 'this', 'function', 'is', 'now', 'taken', 'for', 'granted', 'as', 'an', 'inherent', 'computer'], ['ai', 'is', 'continuously', 'evolving', 'to', 'benefit', 'many', 'different', 'machines', 'are', 'wired', 'using', 'a', 'approach', 'based', 'on', 'computer', 'and'], ['the', 'applications', 'for', 'artificial', 'intelligence', 'are', 'the', 'technology', 'can', 'be', 'applied', 'to', 'many', 'different', 'sectors', 'and', 'ai', 'is', 'being', 'tested', 'and', 'used', 'in', 'the', 'healthcare', 'industry', 'for', 'dosing', 'drugs', 'and', 'different', 'treatment', 'in', 'and', 'for', 'surgical', 'procedures', 'in', 'the', 'operating'], ['other', 'examples', 'of', 'machines', 'with', 'artificial', 'intelligence', 'include', 'computers', 'that', 'play', 'chess', 'and', 'each', 'of', 'these', 'machines', 'must', 'weigh', 'the', 'consequences', 'of', 'any', 'action', 'they', 'as', 'each', 'action', 'will', 'impact', 'the', 'end', 'in', 'the', 'end', 'result', 'is', 'winning', 'the', 'for', 'the', 'computer', 'system', 'must', 'account', 'for', 'all', 'external', 'data', 'and', 'compute', 'it', 'to', 'act', 'in', 'a', 'way', 'that', 'prevents', 'a'], ['artificial', 'intelligence', 'can', 'be', 'divided', 'into', 'two', 'different', 'weak', 'and', 'weak', 'artificial', 'intelligence', 'embodies', 'a', 'system', 'designed', 'to', 'carry', 'out', 'one', 'particular', 'weak', 'ai', 'systems', 'include', 'video', 'games', 'such', 'as', 'the', 'chess', 'example', 'from', 'above', 'and', 'personal', 'assistants', 'such', 'as', 'alexa', 'and', 'you', 'ask', 'the', 'assistant', 'a', 'it', 'answers', 'it', 'for', 'strong', 'artificial', 'intelligence', 'systems', 'are', 'systems', 'that', 'carry', 'on', 'the', 'tasks', 'considered', 'to', 'be', 'these', 'tend', 'to', 'be', 'more', 'complex', 'and', 'complicated', 'they', 'are', 'programmed', 'to', 'handle', 'situations', 'in', 'which', 'they', 'may', 'be', 'required', 'to', 'problem', 'solve', 'without', 'having', 'a', 'person', 'these', 'kinds', 'of', 'systems', 'can', 'be', 'found', 'in', 'applications', 'like', 'cars', 'or', 'in', 'hospital', 'operating']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_content=list()\n",
    "for i in range(len(normailzed_content)):\n",
    "  tokenized_content.append(nltk.word_tokenize(normailzed_content[i]))\n",
    "print(tokenized_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GX3ZnlOZqNQ-"
   },
   "source": [
    "**STOPWORD REMOVAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HdJuj1lqr65c",
    "outputId": "bdade490-7675-4cfe-f91d-1c291292784c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords') #downloading the necessary corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qoAE9I-no9iC",
    "outputId": "58170ef8-78a6-49e8-a703-644dd30f68ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#displaying the stopwords of english language\n",
    "from nltk.corpus import *\n",
    "\n",
    "stopwords=nltk.corpus.stopwords.words(fileids='english')\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmXWAXSnr2x_",
    "outputId": "c3ac2970-5440-4fbd-b845-3d09109ae1d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['artificial', 'intelligence', 'refers', 'simulation', 'human', 'intelligence', 'machines', 'programmed', 'think', 'like', 'humans', 'mimic', 'term', 'may', 'also', 'applied', 'machine', 'exhibits', 'traits', 'associated', 'human', 'mind', 'learning'], ['artificial', 'intelligence', 'also', 'applications', 'financial', 'used', 'detect', 'flag', 'activity', 'banking', 'finance', 'unusual', 'debit', 'card', 'usage', 'large', 'account', 'help', 'fraud', 'applications', 'ai', 'also', 'used', 'help', 'streamline', 'make', 'trading', 'done', 'making', 'pricing', 'securities', 'easier'], ['ideal', 'characteristic', 'artificial', 'intelligence', 'ability', 'rationalize', 'take', 'actions', 'best', 'chance', 'achieving', 'specific', 'subset', 'artificial', 'intelligence', 'machine', 'refers', 'concept', 'computer', 'programs', 'automatically', 'learn', 'adapt', 'new', 'data', 'without', 'assisted', 'deep', 'learning', 'techniques', 'enable', 'automatic', 'learning', 'absorption', 'huge', 'amounts', 'unstructured', 'data'], ['people', 'hear', 'term', 'artificial', 'first', 'thing', 'usually', 'think', 'films', 'novels', 'weave', 'stories', 'machines', 'wreak', 'havoc', 'nothing', 'could'], ['artificial', 'intelligence', 'based', 'principle', 'human', 'intelligence', 'defined', 'way', 'machine', 'easily', 'mimic', 'execute', 'simple', 'even', 'goals', 'artificial', 'intelligence', 'include', 'mimicking', 'human', 'cognitive', 'researchers', 'developers', 'field', 'making', 'surprisingly', 'rapid', 'strides', 'mimicking', 'activities', 'extent', 'concretely', 'believe', 'innovators', 'may', 'soon', 'able', 'develop', 'systems', 'exceed', 'capacity', 'humans', 'learn', 'reason', 'others', 'remain', 'skeptical', 'cognitive', 'activity', 'laced', 'value', 'judgments', 'subject', 'human'], ['technology', 'previous', 'benchmarks', 'defined', 'artificial', 'intelligence', 'become', 'machines', 'calculate', 'basic', 'functions', 'recognize', 'text', 'optical', 'character', 'recognition', 'longer', 'considered', 'embody', 'artificial', 'since', 'function', 'taken', 'granted', 'inherent', 'computer'], ['ai', 'continuously', 'evolving', 'benefit', 'many', 'different', 'machines', 'wired', 'using', 'approach', 'based', 'computer'], ['applications', 'artificial', 'intelligence', 'technology', 'applied', 'many', 'different', 'sectors', 'ai', 'tested', 'used', 'healthcare', 'industry', 'dosing', 'drugs', 'different', 'treatment', 'surgical', 'procedures', 'operating'], ['examples', 'machines', 'artificial', 'intelligence', 'include', 'computers', 'play', 'chess', 'machines', 'must', 'weigh', 'consequences', 'action', 'action', 'impact', 'end', 'end', 'result', 'winning', 'computer', 'system', 'must', 'account', 'external', 'data', 'compute', 'act', 'way', 'prevents'], ['artificial', 'intelligence', 'divided', 'two', 'different', 'weak', 'weak', 'artificial', 'intelligence', 'embodies', 'system', 'designed', 'carry', 'one', 'particular', 'weak', 'ai', 'systems', 'include', 'video', 'games', 'chess', 'example', 'personal', 'assistants', 'alexa', 'ask', 'assistant', 'answers', 'strong', 'artificial', 'intelligence', 'systems', 'systems', 'carry', 'tasks', 'considered', 'tend', 'complex', 'complicated', 'programmed', 'handle', 'situations', 'may', 'required', 'problem', 'solve', 'without', 'person', 'kinds', 'systems', 'found', 'applications', 'like', 'cars', 'hospital', 'operating']]\n"
     ]
    }
   ],
   "source": [
    "#removing stopwords from content\n",
    "stopword_removed_content=list()\n",
    "for i in range(len(tokenized_content)):\n",
    "  stopword_removed_content.append([w for w in tokenized_content[i] if w not in stopwords])\n",
    "print(stopword_removed_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDR4gu2ctVlT"
   },
   "source": [
    "**STEMMING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yqFCXVPIXGDE",
    "outputId": "fa6b7823-5bf1-4dfa-8a7a-5bd66eaa86f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artifici intellig refer simul human intellig machin program think like human mimic term may also appli machin exhibit trait associ human mind learn', 'artifici intellig also applic financi use detect flag activ bank financ unusu debit card usag larg account help fraud applic ai also use help streamlin make trade done make price secur easier', 'ideal characterist artifici intellig abil ration take action best chanc achiev specif subset artifici intellig machin refer concept comput program automat learn adapt new data without assist deep learn techniqu enabl automat learn absorpt huge amount unstructur data', 'peopl hear term artifici first thing usual think film novel weav stori machin wreak havoc noth could', 'artifici intellig base principl human intellig defin way machin easili mimic execut simpl even goal artifici intellig includ mimick human cognit research develop field make surprisingli rapid stride mimick activ extent concret believ innov may soon abl develop system exceed capac human learn reason other remain skeptic cognit activ lace valu judgment subject human', 'technolog previou benchmark defin artifici intellig becom machin calcul basic function recogn text optic charact recognit longer consid embodi artifici sinc function taken grant inher comput', 'ai continu evolv benefit mani differ machin wire use approach base comput', 'applic artifici intellig technolog appli mani differ sector ai test use healthcar industri dose drug differ treatment surgic procedur oper', 'exampl machin artifici intellig includ comput play chess machin must weigh consequ action action impact end end result win comput system must account extern data comput act way prevent', 'artifici intellig divid two differ weak weak artifici intellig embodi system design carri one particular weak ai system includ video game chess exampl person assist alexa ask assist answer strong artifici intellig system system carri task consid tend complex complic program handl situat may requir problem solv without person kind system found applic like car hospit oper']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "final=[]\n",
    "for i in range(len(stopword_removed_content)):\n",
    "    final.append(' '.join([ps.stem(word) for word in stopword_removed_content[i]]))\n",
    "print(final)\n",
    "#pre-processing of text ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bN-lec0_YhhN"
   },
   "source": [
    "**Converting the corpus into Bag-of-Words and tf-idf feature matrix using:**  \n",
    "**(a) TfidfVectorizer() and CountVectorizer**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3WGbh4RYmkt",
    "outputId": "2cc74201-6e25-4a97-c644-fcbf511f920a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [3.30258509 0.         3.30258509 ... 0.         2.60943791 0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         2.60943791 0.        ]]\n",
      "['abil', 'abl', 'absorpt', 'account', 'achiev', 'act', 'action', 'activ', 'adapt', 'ai', 'alexa', 'also', 'amount', 'answer', 'appli', 'applic', 'approach', 'artifici', 'ask', 'assist', 'associ', 'automat', 'bank', 'base', 'basic', 'becom', 'believ', 'benchmark', 'benefit', 'best', 'calcul', 'capac', 'car', 'card', 'carri', 'chanc', 'charact', 'characterist', 'chess', 'cognit', 'complex', 'complic', 'comput', 'concept', 'concret', 'consequ', 'consid', 'continu', 'could', 'data', 'debit', 'deep', 'defin', 'design', 'detect', 'develop', 'differ', 'divid', 'done', 'dose', 'drug', 'easier', 'easili', 'embodi', 'enabl', 'end', 'even', 'evolv', 'exampl', 'exceed', 'execut', 'exhibit', 'extent', 'extern', 'field', 'film', 'financ', 'financi', 'first', 'flag', 'found', 'fraud', 'function', 'game', 'goal', 'grant', 'handl', 'havoc', 'healthcar', 'hear', 'help', 'hospit', 'huge', 'human', 'ideal', 'impact', 'includ', 'industri', 'inher', 'innov', 'intellig', 'judgment', 'kind', 'lace', 'larg', 'learn', 'like', 'longer', 'machin', 'make', 'mani', 'may', 'mimic', 'mimick', 'mind', 'must', 'new', 'noth', 'novel', 'one', 'oper', 'optic', 'other', 'particular', 'peopl', 'person', 'play', 'prevent', 'previou', 'price', 'principl', 'problem', 'procedur', 'program', 'rapid', 'ration', 'reason', 'recogn', 'recognit', 'refer', 'remain', 'requir', 'research', 'result', 'sector', 'secur', 'simpl', 'simul', 'sinc', 'situat', 'skeptic', 'solv', 'soon', 'specif', 'stori', 'streamlin', 'stride', 'strong', 'subject', 'subset', 'surgic', 'surprisingli', 'system', 'take', 'taken', 'task', 'techniqu', 'technolog', 'tend', 'term', 'test', 'text', 'thing', 'think', 'trade', 'trait', 'treatment', 'two', 'unstructur', 'unusu', 'usag', 'use', 'usual', 'valu', 'video', 'way', 'weak', 'weav', 'weigh', 'win', 'wire', 'without', 'wreak']\n"
     ]
    }
   ],
   "source": [
    "#using TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf=TfidfVectorizer(smooth_idf=False,norm=False)\n",
    "X=tf.fit_transform(final)\n",
    "print(X.toarray())\n",
    "print(tf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XCKAIDLWZFpg",
    "outputId": "583ecb19-789d-467e-83ff-67842e7b9a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                abil       abl   absorpt  ...      wire   without     wreak\n",
      "file1.txt   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
      "file2.txt   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
      "file3.txt   3.302585  0.000000  3.302585  ...  0.000000  2.609438  0.000000\n",
      "file4.txt   0.000000  0.000000  0.000000  ...  0.000000  0.000000  3.302585\n",
      "file5.txt   0.000000  3.302585  0.000000  ...  0.000000  0.000000  0.000000\n",
      "file6.txt   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
      "file7.txt   0.000000  0.000000  0.000000  ...  3.302585  0.000000  0.000000\n",
      "file8.txt   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
      "file10.txt  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
      "file9.txt   0.000000  0.000000  0.000000  ...  0.000000  2.609438  0.000000\n",
      "\n",
      "[10 rows x 193 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tf_bow=pd.DataFrame(data=X.toarray(),columns=tf.get_feature_names(),index=filenames)\n",
    "print(tf_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZejXdHXPZ4ib",
    "outputId": "5ad58bba-a365-4680-b058-0da529cac359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]]\n",
      "['abil', 'abl', 'absorpt', 'account', 'achiev', 'act', 'action', 'activ', 'adapt', 'ai', 'alexa', 'also', 'amount', 'answer', 'appli', 'applic', 'approach', 'artifici', 'ask', 'assist', 'associ', 'automat', 'bank', 'base', 'basic', 'becom', 'believ', 'benchmark', 'benefit', 'best', 'calcul', 'capac', 'car', 'card', 'carri', 'chanc', 'charact', 'characterist', 'chess', 'cognit', 'complex', 'complic', 'comput', 'concept', 'concret', 'consequ', 'consid', 'continu', 'could', 'data', 'debit', 'deep', 'defin', 'design', 'detect', 'develop', 'differ', 'divid', 'done', 'dose', 'drug', 'easier', 'easili', 'embodi', 'enabl', 'end', 'even', 'evolv', 'exampl', 'exceed', 'execut', 'exhibit', 'extent', 'extern', 'field', 'film', 'financ', 'financi', 'first', 'flag', 'found', 'fraud', 'function', 'game', 'goal', 'grant', 'handl', 'havoc', 'healthcar', 'hear', 'help', 'hospit', 'huge', 'human', 'ideal', 'impact', 'includ', 'industri', 'inher', 'innov', 'intellig', 'judgment', 'kind', 'lace', 'larg', 'learn', 'like', 'longer', 'machin', 'make', 'mani', 'may', 'mimic', 'mimick', 'mind', 'must', 'new', 'noth', 'novel', 'one', 'oper', 'optic', 'other', 'particular', 'peopl', 'person', 'play', 'prevent', 'previou', 'price', 'principl', 'problem', 'procedur', 'program', 'rapid', 'ration', 'reason', 'recogn', 'recognit', 'refer', 'remain', 'requir', 'research', 'result', 'sector', 'secur', 'simpl', 'simul', 'sinc', 'situat', 'skeptic', 'solv', 'soon', 'specif', 'stori', 'streamlin', 'stride', 'strong', 'subject', 'subset', 'surgic', 'surprisingli', 'system', 'take', 'taken', 'task', 'techniqu', 'technolog', 'tend', 'term', 'test', 'text', 'thing', 'think', 'trade', 'trait', 'treatment', 'two', 'unstructur', 'unusu', 'usag', 'use', 'usual', 'valu', 'video', 'way', 'weak', 'weav', 'weigh', 'win', 'wire', 'without', 'wreak']\n"
     ]
    }
   ],
   "source": [
    "#using CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "Y=cv.fit_transform(final)\n",
    "print(Y.toarray())\n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imWvS4zGaOso",
    "outputId": "09c8b816-5c91-4705-8840-76c58bc9c1f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            abil  abl  absorpt  account  ...  win  wire  without  wreak\n",
      "file1.txt      0    0        0        0  ...    0     0        0      0\n",
      "file2.txt      0    0        0        1  ...    0     0        0      0\n",
      "file3.txt      1    0        1        0  ...    0     0        1      0\n",
      "file4.txt      0    0        0        0  ...    0     0        0      1\n",
      "file5.txt      0    1        0        0  ...    0     0        0      0\n",
      "file6.txt      0    0        0        0  ...    0     0        0      0\n",
      "file7.txt      0    0        0        0  ...    0     1        0      0\n",
      "file8.txt      0    0        0        0  ...    0     0        0      0\n",
      "file10.txt     0    0        0        1  ...    1     0        0      0\n",
      "file9.txt      0    0        0        0  ...    0     0        1      0\n",
      "\n",
      "[10 rows x 193 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cv_bow=pd.DataFrame(data=Y.toarray(),columns=tf.get_feature_names(),index=filenames)\n",
    "print(cv_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwnzIGc_a2FO"
   },
   "source": [
    "**(b) Without using in-built functions**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HBL7aA-Ta6Rc",
    "outputId": "2015979e-2094-46bd-ceab-21cac4f55574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file1.txt': {'artifici': 1, 'intellig': 2, 'refer': 1, 'simul': 1, 'human': 3, 'machin': 2, 'program': 1, 'think': 1, 'like': 1, 'mimic': 1, 'term': 1, 'may': 1, 'also': 1, 'appli': 1, 'exhibit': 1, 'trait': 1, 'associ': 1, 'mind': 1, 'learn': 1}, 'file2.txt': {'artifici': 1, 'intellig': 1, 'also': 2, 'applic': 2, 'financi': 1, 'use': 2, 'detect': 1, 'flag': 1, 'activ': 1, 'bank': 1, 'financ': 1, 'unusu': 1, 'debit': 1, 'card': 1, 'usag': 1, 'larg': 1, 'account': 1, 'help': 2, 'fraud': 1, 'ai': 1, 'streamlin': 1, 'make': 2, 'trade': 1, 'done': 1, 'price': 1, 'secur': 1, 'easier': 1}, 'file3.txt': {'ideal': 1, 'characterist': 1, 'artifici': 2, 'intellig': 2, 'abil': 1, 'ration': 1, 'take': 1, 'action': 1, 'best': 1, 'chanc': 1, 'achiev': 1, 'specif': 1, 'subset': 1, 'machin': 1, 'refer': 1, 'concept': 1, 'comput': 1, 'program': 1, 'automat': 2, 'learn': 3, 'adapt': 1, 'new': 1, 'data': 2, 'without': 1, 'assist': 1, 'deep': 1, 'techniqu': 1, 'enabl': 1, 'absorpt': 1, 'huge': 1, 'amount': 1, 'unstructur': 1}, 'file4.txt': {'peopl': 1, 'hear': 1, 'term': 1, 'artifici': 1, 'first': 1, 'thing': 1, 'usual': 1, 'think': 1, 'film': 1, 'novel': 1, 'weav': 1, 'stori': 1, 'machin': 1, 'wreak': 1, 'havoc': 1, 'noth': 1, 'could': 1}, 'file5.txt': {'artifici': 2, 'intellig': 3, 'base': 1, 'principl': 1, 'human': 4, 'defin': 1, 'way': 1, 'machin': 1, 'easili': 1, 'mimic': 1, 'execut': 1, 'simpl': 1, 'even': 1, 'goal': 1, 'includ': 1, 'mimick': 2, 'cognit': 2, 'research': 1, 'develop': 2, 'field': 1, 'make': 1, 'surprisingli': 1, 'rapid': 1, 'stride': 1, 'activ': 2, 'extent': 1, 'concret': 1, 'believ': 1, 'innov': 1, 'may': 1, 'soon': 1, 'abl': 1, 'system': 1, 'exceed': 1, 'capac': 1, 'learn': 1, 'reason': 1, 'other': 1, 'remain': 1, 'skeptic': 1, 'lace': 1, 'valu': 1, 'judgment': 1, 'subject': 1}, 'file6.txt': {'technolog': 1, 'previou': 1, 'benchmark': 1, 'defin': 1, 'artifici': 2, 'intellig': 1, 'becom': 1, 'machin': 1, 'calcul': 1, 'basic': 1, 'function': 2, 'recogn': 1, 'text': 1, 'optic': 1, 'charact': 1, 'recognit': 1, 'longer': 1, 'consid': 1, 'embodi': 1, 'sinc': 1, 'taken': 1, 'grant': 1, 'inher': 1, 'comput': 1}, 'file7.txt': {'ai': 1, 'continu': 1, 'evolv': 1, 'benefit': 1, 'mani': 1, 'differ': 1, 'machin': 1, 'wire': 1, 'use': 1, 'approach': 1, 'base': 1, 'comput': 1}, 'file8.txt': {'applic': 1, 'artifici': 1, 'intellig': 1, 'technolog': 1, 'appli': 1, 'mani': 1, 'differ': 2, 'sector': 1, 'ai': 1, 'test': 1, 'use': 1, 'healthcar': 1, 'industri': 1, 'dose': 1, 'drug': 1, 'treatment': 1, 'surgic': 1, 'procedur': 1, 'oper': 1}, 'file10.txt': {'exampl': 1, 'machin': 2, 'artifici': 1, 'intellig': 1, 'includ': 1, 'comput': 3, 'play': 1, 'chess': 1, 'must': 2, 'weigh': 1, 'consequ': 1, 'action': 2, 'impact': 1, 'end': 2, 'result': 1, 'win': 1, 'system': 1, 'account': 1, 'extern': 1, 'data': 1, 'act': 1, 'way': 1, 'prevent': 1}, 'file9.txt': {'artifici': 3, 'intellig': 3, 'divid': 1, 'two': 1, 'differ': 1, 'weak': 3, 'embodi': 1, 'system': 5, 'design': 1, 'carri': 2, 'one': 1, 'particular': 1, 'ai': 1, 'includ': 1, 'video': 1, 'game': 1, 'chess': 1, 'exampl': 1, 'person': 2, 'assist': 2, 'alexa': 1, 'ask': 1, 'answer': 1, 'strong': 1, 'task': 1, 'consid': 1, 'tend': 1, 'complex': 1, 'complic': 1, 'program': 1, 'handl': 1, 'situat': 1, 'may': 1, 'requir': 1, 'problem': 1, 'solv': 1, 'without': 1, 'kind': 1, 'found': 1, 'applic': 1, 'like': 1, 'car': 1, 'hospit': 1, 'oper': 1}}\n"
     ]
    }
   ],
   "source": [
    "#count vectorization\n",
    "count={}\n",
    "for i in range(len(final)):\n",
    "    word_count={}\n",
    "    for word in final[i].split():\n",
    "        if word not in word_count.keys():\n",
    "            word_count[word]=0\n",
    "        word_count[word]+=1\n",
    "    count[filenames[i]]=word_count\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6OSVmQHNbMug",
    "outputId": "0955f2e1-c1bb-4422-9fba-918d0a967f5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          file1.txt  file2.txt  file3.txt  ...  file8.txt  file10.txt  file9.txt\n",
      "artifici        1.0        1.0        2.0  ...        1.0         1.0        3.0\n",
      "intellig        2.0        1.0        2.0  ...        1.0         1.0        3.0\n",
      "refer           1.0        0.0        1.0  ...        0.0         0.0        0.0\n",
      "simul           1.0        0.0        0.0  ...        0.0         0.0        0.0\n",
      "human           3.0        0.0        0.0  ...        0.0         0.0        0.0\n",
      "...             ...        ...        ...  ...        ...         ...        ...\n",
      "solv            0.0        0.0        0.0  ...        0.0         0.0        1.0\n",
      "kind            0.0        0.0        0.0  ...        0.0         0.0        1.0\n",
      "found           0.0        0.0        0.0  ...        0.0         0.0        1.0\n",
      "car             0.0        0.0        0.0  ...        0.0         0.0        1.0\n",
      "hospit          0.0        0.0        0.0  ...        0.0         0.0        1.0\n",
      "\n",
      "[193 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "cv_bow1=pd.DataFrame(data=count)\n",
    "cv_bow1.fillna(0,inplace=True)\n",
    "print(cv_bow1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCx5wxl9ijl-"
   },
   "source": [
    "# **Link to the Corpus Used**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q35FaD-7ixc3"
   },
   "source": [
    "[Click here to see the corpus used for the entire pre-processing](https://drive.google.com/drive/folders/1HzbobbAoPh-irlajzesJvG6Wuy3y5RJT?usp=sharing)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Conversational AI_Asignment-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
