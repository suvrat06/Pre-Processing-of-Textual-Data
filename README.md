# Pre-Processing-of-Textual-Data

This notebook depicts the various steps involved in the pre-processing of textual data. In order to enuse smooth interpretation of text by machines a lot pre-processing is required - bag of words is done of the most popular ways to represent textual data for machines to process it. Here, I've taken a sample corpus (link provided at the end) which contains 10 txt files. We will be converting the corpus into bag of words (both count vector and tf-idf vector) through a series of steps. For the sake of understanding - the I've tried to perfom all the steps with and without in-built functions.

Some important terms:

**NLTK:** NLTK stands for Natural Language Tool Kit; it is popular library in python that is used for NLP and text prcoessing

**Corpus:** A collection of texts
